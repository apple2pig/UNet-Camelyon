# âš¡ å¿«é€Ÿå¼€å§‹ - 5 åˆ†é’Ÿä¸Šæ‰‹

## ğŸš€ æœ€å¿«æ–¹å¼ (Copy & Paste)

### ç¬¬ 1 æ­¥: æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ

```bash
# Windows (Command Prompt)
.venv\Scripts\activate

# Windows (PowerShell)
.venv\Scripts\Activate.ps1

# Linux/Mac
source .venv/bin/activate
```

### ç¬¬ 2 æ­¥: è¿›å…¥ skills æ–‡ä»¶å¤¹

```bash
cd skills
```

### ç¬¬ 3 æ­¥: è¿è¡Œä¼˜åŒ–æ¨ç†

**æ–¹å¼ A: è¿è¡Œç¤ºä¾‹è„šæœ¬ï¼ˆæ¨èï¼‰**

```bash
python example_optimized_inference.py
```

**æ–¹å¼ B: è¿è¡Œæ€§èƒ½æµ‹è¯•**

```bash
python compare_inference_speed.py
```

---

## ğŸ“ å¦‚æœéœ€è¦è‡ªå®šä¹‰

### ç¼–è¾‘é…ç½®

æ‰“å¼€ `example_optimized_inference.py`ï¼Œä¿®æ”¹è¿™ä¸‰è¡Œï¼š

```python
# ç¬¬ 16 è¡Œ - æ¨¡å‹è·¯å¾„
model_path='UNet_17.pth'

# ç¬¬ 31 è¡Œ - WSI æ–‡ä»¶è·¯å¾„
wsi_path = '/path/to/your/slide.tif'

# ç¬¬ 58-59 è¡Œ - è¾“å…¥è¾“å‡ºç›®å½•
input_dir = 'your_patches_dir/'
output_dir = 'your_output_dir/'
```

ç„¶åè¿è¡Œï¼š

```bash
python example_optimized_inference.py
```

---

## ğŸ’» è‡ªå·±å†™ä»£ç 

### æœ€ç®€å•çš„æ¨¡æ¿

```python
from inference_optimized import OptimizedInference

# åˆå§‹åŒ–
engine = OptimizedInference('UNet_17.pth')

# å¤„ç† WSI
engine.process_wsi_batched(
    wsi_path='your_slide.tif',
    output_path='result.png'
)
```

### ä¿å­˜ä¸º `my_inference.py`ï¼Œç„¶åè¿è¡Œ

```bash
python my_inference.py
```

---

## ğŸ¯ ä¸‰ä¸ªå¸¸è§ä»»åŠ¡

### ä»»åŠ¡ 1: å¤„ç†å•ä¸ª WSI æ–‡ä»¶

```bash
# ç¼–è¾‘ example_optimized_inference.py
# ä¿®æ”¹ç¬¬ 31 è¡Œçš„ wsi_path
# ç„¶åè¿è¡Œ
python example_optimized_inference.py
```

### ä»»åŠ¡ 2: å¤„ç†ä¸€ä¸ª patch ç›®å½•

```bash
# ç¼–è¾‘ example_optimized_inference.py
# ä¿®æ”¹ç¬¬ 58-59 è¡Œçš„ input_dir å’Œ output_dir
# ç„¶åè¿è¡Œ
python example_optimized_inference.py
```

### ä»»åŠ¡ 3: æµ‹è¯•æ€§èƒ½æå‡

```bash
# ç›´æ¥è¿è¡Œ
python compare_inference_speed.py

# è¾“å‡ºæ€§èƒ½å¯¹æ¯”å’Œå›¾è¡¨
```

---

## âš ï¸ å¸¸è§é”™è¯¯

| é”™è¯¯ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|--------|
| `ModuleNotFoundError` | è™šæ‹Ÿç¯å¢ƒæœªæ¿€æ´» | è¿è¡Œ `.venv\Scripts\activate` |
| `FileNotFoundError` | è·¯å¾„é”™è¯¯ | æ£€æŸ¥æ¨¡å‹/WSI æ–‡ä»¶è·¯å¾„ |
| `CUDA Out of Memory` | GPU æ˜¾å­˜ä¸è¶³ | æ”¹å° `batch_size` æˆ–ç”¨ CPU |
| `OSError: Error loading DLL` | PyTorch é—®é¢˜ | å®‰è£… Visual C++ Runtime |

---

## ğŸ“Š æœŸæœ›ç»“æœ

**æ€§èƒ½æå‡**: 5-6x å¿«é€Ÿ

| æ–¹æ³• | é€Ÿåº¦ |
|------|------|
| åŸå§‹ | ~45ms/patch |
| ä¼˜åŒ– | ~8ms/patch âš¡ |

**æ—¶é—´èŠ‚çœ**:
- 1,000 patches: ä» 45 ç§’ â†’ 8 ç§’
- 57,000 patches (å¤§ WSI): ä» 8 å°æ—¶ â†’ 1 å°æ—¶

---

## ğŸ“š æŸ¥çœ‹å®Œæ•´æ–‡æ¡£

- **è¯¦ç»†æŒ‡å—**: `HOW_TO_RUN_SKILLS.md`
- **ä¼˜åŒ–è¯¦è§£**: `skills/INFERENCE_OPTIMIZATION_README.md`
- **é¡¹ç›®ç»“æ„**: `PROJECT_STRUCTURE.md`
- **ä¸»æ–‡æ¡£**: `README.md`

---

## âœ… ä¸€å¥è¯æ€»ç»“

```bash
# æ¿€æ´»ç¯å¢ƒ
.venv\Scripts\activate

# è¿›å…¥ skills
cd skills

# è¿è¡Œ
python example_optimized_inference.py
```

å®Œæˆï¼ ğŸ‰
